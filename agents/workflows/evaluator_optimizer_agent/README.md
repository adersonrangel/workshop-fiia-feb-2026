# Evaluator-Optimizer Agent - Generador de Planes de Estudio Personalizados

## üìã Descripci√≥n Funcional

Sistema multi-agente que genera planes de estudio personalizados mediante un ciclo iterativo de evaluaci√≥n y refinamiento. A diferencia de pipelines lineales, este sistema implementa un **feedback loop** donde un agente evaluador critica el plan generado y un agente refinador lo mejora hasta cumplir est√°ndares pedag√≥gicos rigurosos.

**Ciclo de mejora continua:**
1. **Generaci√≥n** ‚Üí Crea plan inicial basado en investigaci√≥n (Google Search)
2. **Evaluaci√≥n** ‚Üí Analiza el plan con 8 criterios pedag√≥gicos
3. **Refinamiento** ‚Üí Mejora el plan seg√∫n feedback O sale del loop si est√° optimizado
4. **Repetir** ‚Üí Regresa a evaluaci√≥n (m√°ximo 2 iteraciones)

**Ventajas del patr√≥n evaluator-optimizer:**
- üîÑ **Calidad iterativa:** El plan se refina progresivamente
- üéØ **Criterios objetivos:** Evaluaci√≥n basada en est√°ndares pedag√≥gicos
- üõ°Ô∏è **Salvaguardas:** `max_iterations` previene loops infinitos
- ‚úÖ **Condici√≥n de salida clara:** "LEARNING_OPTIMIZED" termina el ciclo

**Casos de uso:**
- Generaci√≥n de planes de estudio personalizados
- Dise√±o instruccional automatizado
- Sistemas que requieren validaci√≥n antes de output final
- Cualquier tarea que se beneficie de revisi√≥n y refinamiento

## üèóÔ∏è Arquitectura del Sistema

```mermaid
graph TD
    A[Usuario: Solicitud de Plan] --> B[SequentialAgent Pipeline]
    
    B --> C[Agent 1: InitialStudyPlanGenerator]
    C -->|current_plan| D[LoopAgent: Refinement Loop]
    
    D --> E[Agent 2: PedagogicalEvaluator]
    E -->|evaluation| F{Evaluaci√≥n}
    
    F -->|"LEARNING_OPTIMIZED"| G[Agent 3: StudyPlanRefiner]
    F -->|"Feedback"| G
    
    G -->|exit_loop| H[Plan de Estudio Optimizado]
    G -->|current_plan actualizado| E
    
    E -.->|max_iterations=2| H
    
    style C fill:#e3f2fd
    style E fill:#fff3e0
    style G fill:#f1f8e9
    style D fill:#fce4ec
    style H fill:#f3e5f5
    style F fill:#fff9c4
    
    classDef loopNode stroke:#d81b60,stroke-width:3px
    class E,G loopNode
```

> **Nota sobre el loop:** Los agentes E y G forman un ciclo que se repite hasta que la evaluaci√≥n retorna "LEARNING_OPTIMIZED" o se alcanza `max_iterations=2`. La variable `current_plan` se sobrescribe en cada iteraci√≥n del refinador.

### Componentes del Pipeline

#### üîµ Fase 1: Generaci√≥n Inicial

##### 1Ô∏è‚É£ Initial Study Plan Generator Agent
- **Funci√≥n:** Crea plan de estudio inicial basado en requisitos del usuario
- **Herramienta:** Google Search
- **Investiga:**
  - Recursos educativos actualizados sobre el tema
  - Secuencia t√≠pica de aprendizaje
  - Pre-requisitos necesarios
  - Proyectos pr√°cticos recomendados
- **Input del usuario:**
  - Tema a aprender
  - Nivel actual de conocimiento
  - Tiempo disponible (horas/semana)
  - Duraci√≥n deseada del plan
  - Objetivo final espec√≠fico
- **Salida (`current_plan`):** Plan estructurado con fases, objetivos, contenidos, recursos, pr√°cticas y proyecto integrador

#### üî¥ Fase 2: Loop de Refinamiento (max 2 iteraciones)

##### 2Ô∏è‚É£ Pedagogical Evaluator Agent
- **Funci√≥n:** Eval√∫a el plan seg√∫n criterios de dise√±o instruccional
- **Entrada:** `{current_plan}`
- **Criterios de evaluaci√≥n (8 dimensiones):**
  1. ‚úÖ Pre-requisitos claramente identificados y realistas
  2. ‚úÖ Secuenciaci√≥n l√≥gica sin saltos abruptos
  3. ‚úÖ Carga cognitiva manejable
  4. ‚úÖ Balance teor√≠a/pr√°ctica adecuado
  5. ‚úÖ Recursos espec√≠ficos, accesibles y actualizados
  6. ‚úÖ Hitos claros de evaluaci√≥n formativa
  7. ‚úÖ Viabilidad temporal realista
  8. ‚úÖ Proyecto integrador apropiado al nivel
- **Salida (`evaluation`):**
  - `"LEARNING_OPTIMIZED"` si cumple TODOS los criterios
  - Feedback estructurado con 3-4 problemas cr√≠ticos si hay deficiencias

##### 3Ô∏è‚É£ Study Plan Refiner Agent
- **Funci√≥n:** Refina el plan bas√°ndose en feedback o finaliza el loop
- **Herramienta:** `FunctionTool(exit_loop)` - funci√≥n que termina el ciclo
- **Entrada:** `{current_plan}` + `{evaluation}`
- **L√≥gica condicional:**
  - **Si evaluaci√≥n == "LEARNING_OPTIMIZED":**
    - Llama `exit_loop()` ‚Üí termina el loop
  - **Si evaluaci√≥n contiene feedback:**
    - Reescribe el plan incorporando TODAS las sugerencias
    - Mantiene estructura pero mejora contenido
    - Preserva elementos que estaban bien
- **Salida:** `current_plan` actualizado (sobrescribe el anterior)

#### üõ°Ô∏è Salvaguarda: max_iterations=2

Si despu√©s de 2 iteraciones el evaluador sigue encontrando problemas, el loop se detiene autom√°ticamente para evitar ejecuci√≥n infinita. En producci√≥n, este valor podr√≠a ajustarse seg√∫n necesidades.

## üß™ Prompts de Prueba

### Prompt 1: Machine Learning desde cero
```
Quiero aprender Machine Learning desde cero.

Nivel actual: S√© programar en Python (nivel intermedio), conozco matem√°ticas b√°sicas pero no c√°lculo avanzado ni √°lgebra lineal.

Tiempo disponible: 10 horas por semana

Duraci√≥n deseada: 4 meses

Objetivo final: Poder crear y entrenar modelos de clasificaci√≥n y regresi√≥n, y entender cu√°ndo usar cada algoritmo. Quiero aplicarlo en proyectos de an√°lisis de datos.
```

---

### Prompt 2: Desarrollo Web Full Stack (r√°pido)
```
Necesito aprender desarrollo web full stack lo m√°s r√°pido posible.

Nivel actual: Conozco HTML/CSS b√°sico, nunca he programado en JavaScript ni backend.

Tiempo disponible: 20 horas por semana (estoy desempleado y puedo dedicarle tiempo completo)

Duraci√≥n deseada: 8 semanas

Objetivo final: Poder construir y deployar una aplicaci√≥n web completa (tipo to-do list o blog) con autenticaci√≥n de usuarios y base de datos. Busco conseguir trabajo de junior developer.
```

---

## üîÑ Patr√≥n Evaluator-Optimizer Loop

### Cu√°ndo usar este patr√≥n

**‚úÖ Ideal para:**
- Generaci√≥n de contenido que requiere calidad garantizada
- Sistemas donde el output debe cumplir criterios espec√≠ficos
- Tareas que se benefician de revisi√≥n iterativa
- Casos donde hay est√°ndares de evaluaci√≥n claros

**‚ùå NO usar para:**
- Tareas simples sin necesidad de refinamiento
- Cuando la evaluaci√≥n es subjetiva sin criterios claros
- Procesos donde cada iteraci√≥n es costosa (tiempo/dinero)
- Casos donde el primer intento es suficiente

### Comparaci√≥n de Patrones

| Aspecto | LoopAgent (Evaluator-Optimizer) | SequentialAgent | ParallelAgent |
|---------|--------------------------------|-----------------|---------------|
| **Flujo** | C√≠clico con condici√≥n de salida | Lineal A‚ÜíB‚ÜíC | Simult√°neo A+B+C |
| **Iteraciones** | M√∫ltiples (hasta max_iterations) | 1 vez | 1 vez |
| **Dependencias** | Output se retroalimenta | Cada agente depende del anterior | Agentes independientes |
| **Garant√≠a de calidad** | Alta (validaci√≥n iterativa) | Media | Media |
| **Costo computacional** | Alto (m√∫ltiples pasadas) | Medio | Medio |
| **Mejor para** | Refinamiento hasta criterios | Pipeline lineal de transformaciones | Investigaci√≥n paralela |

### Componentes Clave del Patr√≥n

#### 1. Condici√≥n de Salida Clara
```python
# El evaluador retorna exactamente "LEARNING_OPTIMIZED"
# El refiner detecta esta string y llama exit_loop()
```

**Importante:** La condici√≥n debe ser inequ√≠voca y verificable.

#### 2. Funci√≥n de Salida del Loop
```python
def exit_loop():
    """Termina el loop cuando se alcanza el estado √≥ptimo"""
    return {"status": "optimized", "message": "..."}
```

Herramienta especial (`FunctionTool`) que el agente refiner puede llamar.

#### 3. Variable que se Sobrescribe
```python
output_key="current_plan"  # Se actualiza en cada iteraci√≥n
```

La misma variable se lee, eval√∫a, modifica y vuelve a evaluar.

#### 4. L√≠mite de Iteraciones
```python
max_iterations=2  # Salvaguarda contra loops infinitos
```

**Recomendaciones:**
- Desarrollo/testing: 2-3 iteraciones
- Producci√≥n: 3-5 iteraciones seg√∫n complejidad
- Monitorear cu√°ntas iteraciones se usan realmente

### Errores Comunes a Evitar

‚ùå **Condici√≥n de salida ambigua**
- Malo: "El plan est√° bien" (subjetivo)
- Bueno: "LEARNING_OPTIMIZED" (string exacta)

‚ùå **No definir max_iterations**
- Siempre incluir salvaguarda

‚ùå **Evaluador que modifica**
- Evaluator solo critica, Refiner modifica
- Separaci√≥n de responsabilidades clara

‚ùå **Olvida manejar ambos casos en el Refiner**
- Debe tener l√≥gica para "optimizado" Y "feedback"

## üí° Notas de Implementaci√≥n

**Gesti√≥n del output_key:**
- `current_plan` es creado por Generator
- Le√≠do por Evaluator (no lo modifica)
- Sobrescrito por Refiner (mismo key)
- El loop mantiene la versi√≥n m√°s reciente

**Herramienta exit_loop:**
- Solo el Refiner tiene acceso a `FunctionTool(exit_loop)`
- El Evaluator NO puede terminar el loop directamente
- Separa responsabilidad: Evaluator decide SI salir, Refiner ejecuta la salida

**Optimizaci√≥n de Google Search:**
- Solo Generator usa Google Search (no los agentes en el loop)
- Reduce costos y tiempo al no buscar en cada iteraci√≥n
- El Refiner mejora bas√°ndose en conocimiento del LLM + feedback
